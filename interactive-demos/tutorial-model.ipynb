{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom model tutorial\n",
    "\n",
    "In this notebook, you will learn how to replace the default network model with your own customized model following below 5 steps.\n",
    "\n",
    "(0. Preparation of this notebook)\n",
    "1. Setting up the training environment \n",
    "2. Build customized Q-funciton model for training\n",
    "3. Create a ModelBuilder\n",
    "4. Setup the DQN algorithm\n",
    "5. Run the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Let's start by first installing nnabla-rl and importing required packages for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nnabla-rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import nnabla as nn\n",
    "from nnabla import functions as NF\n",
    "from nnabla import parametric_functions as NPF\n",
    "\n",
    "import nnabla_rl\n",
    "import nnabla_rl.algorithms as A\n",
    "import nnabla_rl.functions as RF\n",
    "import nnabla_rl.writers as W\n",
    "from nnabla_rl.builders import ModelBuilder, SolverBuilder\n",
    "from nnabla_rl.models.q_function import DiscreteQFunction\n",
    "from nnabla_rl.environments.wrappers import NumpyFloat32Env, ScreenRenderEnv\n",
    "from nnabla_rl.utils.evaluator import EpisodicEvaluator\n",
    "from nnabla_rl.utils.reproductions import set_global_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash package_install.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./colab_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.clear_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the training environment\n",
    "\n",
    "Set up the \"MountainCar\" environment provided by the OpenAI Gym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_env(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    env = NumpyFloat32Env(env)\n",
    "    env = ScreenRenderEnv(env)  # for rendering screen\n",
    "    env.seed(0) # optinal\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"MountainCar-v0\"\n",
    "env = build_env(env_name)\n",
    "set_global_seed(0) # optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build customized Q-function model for training\n",
    "\n",
    "Let's prepare a customized network model for the training of \"MountainCar\".  \n",
    "The DQN algorithm that we will use in this notebook requires a model of Q-function to train.  \n",
    "So we will implement a customized Q-function model in this notebook.  \n",
    "Implementing Q-function is easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MountainCarQFunction(DiscreteQFunction):\n",
    "    def __init__(self, scope_name: str, n_action: int):\n",
    "        super(MountainCarQFunction, self).__init__(scope_name)\n",
    "        self._n_action = n_action\n",
    "    \n",
    "    def all_q(self, s: nn.Variable) -> nn.Variable:\n",
    "        with nn.parameter_scope(self.scope_name):\n",
    "            h = NF.relu(NPF.affine(s, 50, name=\"affine-1\"))\n",
    "            h = NF.relu(NPF.affine(h, 50, name=\"affine-2\"))\n",
    "            q = NPF.affine(h, self._n_action, name=\"pred-q\")\n",
    "        return q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a ModelBuilder\n",
    "\n",
    "To use your customized model, you'll need to create a ModelBuilder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MountainCarQFunctionBuilder(ModelBuilder[QFunction]):\n",
    "    def build_model(self, scope_name, env_info, algorithm_params, **kwargs):\n",
    "        return MountainCarQFunction(scope_name, env_info.action_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the DQN algorithm\n",
    "\n",
    "We are almost ready to start the training. Finally, let's set up the DQN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = A.DQNConfig(\n",
    "    gpu_id=0,\n",
    "    gamma=0.9,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=32,\n",
    "    learner_update_frequency=1,\n",
    "    target_update_frequency=200,\n",
    "    start_timesteps=200,\n",
    "    replay_buffer_size=10000,\n",
    "    max_explore_steps=10000,\n",
    "    initial_epsilon=1.0,\n",
    "    final_epsilon=0.001,\n",
    "    test_epsilon=0.05,\n",
    "    grad_clip=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dqn = A.DQN(\n",
    "    env,\n",
    "    config=config,\n",
    "    q_func_builder=MountainCarQFunctionBuilder() # Feeding the builder to use customized model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hook (optional)\n",
    "\n",
    "We will append a RenderHook to the algorithm to visually check the training statusï¼ŽThis step is optional.\n",
    "This hook may slow down the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_hook = RenderHook(env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.set_hooks([render_hook])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training\n",
    "\n",
    "The training takes time (10-20 min).  \n",
    "After 10-20 min, you will see the cart reaching to the flag on the top of mountain  (Not always, in some trials)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dqn.train(env, total_iterations=100000)\n",
    "finally:\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}